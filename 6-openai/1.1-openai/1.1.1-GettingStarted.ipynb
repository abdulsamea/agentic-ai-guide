{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000021B4BA1F250> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000021B4BAE07D0> root_client=<openai.OpenAI object at 0x0000021B2D0DB610> root_async_client=<openai.AsyncOpenAI object at 0x0000021B4BA1FD90> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a class of artificial intelligence systems designed to generate new content, such as text, images, audio, or video, that resembles existing data. These systems use machine learning models to learn patterns and structures from data, allowing them to produce novel outputs. Key technologies behind generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These systems consist of two neural networks, a generator and a discriminator, that work together in a competitive setting. The generator creates new data instances, while the discriminator evaluates them against real data, guiding the generator to produce increasingly realistic outputs.\\n\\n2. **Variational Autoencoders (VAEs):** These involve encoding input data into a latent space and then decoding it to reconstruct the original data. They can manipulate the latent space to generate new data that is similar to the training set.\\n\\n3. **Transformer Models:** Often used in natural language processing, these models can generate text based on input data, as demonstrated by GPT (Generative Pre-trained Transformer) models. They excel at understanding context and semantics in language, allowing them to produce coherent and contextually relevant text.\\n\\nGenerative AI has numerous applications, including content creation, design, personalization, and simulation, and it continues to evolve, offering increasingly sophisticated capabilities.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 259, 'prompt_tokens': 13, 'total_tokens': 272, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BqjYOlbRZVBcdk6RVGSZkUWwwzbIq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--68e9ee45-fa52-4d9a-980f-9620ae0c28a3-0' usage_metadata={'input_tokens': 13, 'output_tokens': 259, 'total_tokens': 272, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith is a suite of tools and services developed by LangChain to support the development and deployment of applications leveraging large language models (LLMs). It aims to improve the production readiness of applications by offering capabilities to trace, evaluate, test, and monitor LLM applications with a focus on quality, reliability, and user experience.\\n\\nKey features of Langsmith include:\\n\\n1. **Tracing**: Allows developers to trace and visualize how data flows through their system, helping to debug and understand application workflows.\\n\\n2. **Evaluation**: Provides facilities to evaluate the performance and accuracy of LLM applications, offering metrics and insights that can inform improvements and optimizations.\\n\\n3. **Testing**: Aids in the automated testing of LLM applications to ensure they perform as expected across a variety of scenarios, promoting robust and reliable models in production.\\n\\n4. **Monitoring**: Offers tools to monitor the performance and behavior of LLMs in real-time, enabling proactive management and troubleshooting.\\n\\nLangsmith is designed to integrate seamlessly with LangChain's framework, making it easier for developers to enhance their workflows without the need for extensive custom development. It is a valuable toolset for those looking to build scalable, efficient, and high-performing language model applications.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 246, 'prompt_tokens': 33, 'total_tokens': 279, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BqjahMam3Cit5rCS49kBo4Yolg1D0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--e7978120-c4e6-467b-aa91-b2ac922f8173-0' usage_metadata={'input_tokens': 33, 'output_tokens': 246, 'total_tokens': 279, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool and platform designed to enhance the development and deployment of applications using language models. It provides developers with sophisticated tools to debug, test, evaluate, and monitor their language model-based applications. The primary goal of Langsmith is to ensure that developers can effectively manage the complexities associated with language models, especially when integrating them into larger applications.\n",
      "\n",
      "Key features of Langsmith include:\n",
      "\n",
      "1. **Tracing**: Helps developers visualize and trace the execution flow of their applications, making it easier to understand how different components, such as prompts and model outputs, interact over time.\n",
      "   \n",
      "2. **Testing and Evaluation**: Provides capabilities to test language model outputs against expected results. This is crucial for maintaining the quality and performance of applications that depend on language models.\n",
      "\n",
      "3. **Monitoring**: Offers tools to monitor the performance of language models in production, allowing developers to identify issues and optimize the model's performance.\n",
      "\n",
      "4. **Integration Support**: Seamlessly integrates with LangChain, a popular framework used for building applications powered by language models. This integration allows developers to leverage the full potential of LangChain's features in conjunction with Langsmith's debugging and monitoring capabilities.\n",
      "\n",
      "Overall, Langsmith is designed to empower developers to build more robust, efficient, and effective applications by addressing the key challenges of working with advanced language models.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Cheesecake is a rich and creamy dessert that typically consists of a mixture of soft, fresh cheese, eggs, and sugar. This mixture is usually placed on a crust made from crushed cookies, graham crackers, or pastry. Here are some key points about cheesecakes:\n",
      "\n",
      "1. **Varieties**: Cheesecake comes in many varieties. The most popular types include New York-style cheesecake, known for its dense and rich texture, and Italian-style cheesecake, which uses ricotta cheese to create a lighter consistency. There are also other regional versions like Japanese cotton cheesecake, which is airy and soufflé-like.\n",
      "\n",
      "2. **Ingredients**: The base ingredient is usually cream cheese, although other soft cheeses like ricotta or mascarpone can be used. The additional ingredients can include eggs, sugar, and flavorings such as vanilla or lemon zest. Some recipes also include sour cream to add an extra layer of creaminess and tanginess.\n",
      "\n",
      "3. **Baking vs. No-Bake**: Cheesecakes can be either baked or prepared without baking. Baked cheesecakes are often cooked in a water bath to prevent them from cracking and ensure even cooking. No-bake cheesecakes are set using gelatin or whipped cream and are typically chilled in the refrigerator until firm.\n",
      "\n",
      "4. **Toppings and Flavors**: Cheesecakes can be enhanced with various toppings and flavors, such as fruit compotes, chocolate, caramel, nuts, or even savory ingredients. Popular flavors include strawberry, blueberry, key lime, and chocolate.\n",
      "\n",
      "5. **Cultural Variations**: Different cultures have their own unique take on cheesecake. For example, the German \"Käsekuchen\" uses quark cheese and sometimes includes a yeast dough crust, while French cheesecakes often incorporate a pastry shell and may use Neufchâtel cheese.\n",
      "\n",
      "6. **Storage**: Cheesecake is best stored in the refrigerator and can generally last for several days. It can also be frozen for longer-term storage, although the texture might change slightly upon thawing.\n",
      "\n",
      "Cheesecake is a versatile dessert that can be adapted with different ingredients and techniques to cater to a wide range of tastes and preferences.\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"Can you tell me some info about cheesecakes?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
